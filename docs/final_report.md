# 시계열 이상 탐지(TSAD) 비교 분석 보고서

**Prediction-based vs Reconstruction-based 접근법 비교**

---

## 목차

1. [프로젝트 개요](#1-프로젝트-개요)
2. [데이터셋 소개](#2-데이터셋-소개)
3. [탐색적 데이터 분석 (EDA)](#3-탐색적-데이터-분석-eda)
4. [방법론](#4-방법론)
5. [실험 설계](#5-실험-설계)
6. [실험 결과](#6-실험-결과)
7. [결과 분석 및 인사이트](#7-결과-분석-및-인사이트)
8. [결론 및 향후 연구](#8-결론-및-향후-연구)

---

## 📌 그림 삽입 목록 (Word 편집 시 대체)

| 그림 번호 | 위치 (섹션) | 내용 | 노트북 셀 |
|----------|------------|------|----------|
| **그림 1** | 2.4 | PSM/SWaT 이상치 분포 파이 차트 | `cell-19` (섹션 5. 이상치 분포 분석) |
| **그림 2** | 3.2 | STL 분해 결과 (4단 그래프) | `cell-15` (섹션 4. Trend/Seasonal 분해) |
| **그림 3** | 3.3 | 상관관계 히트맵 | `cell-21, cell-22` (섹션 6. 상관관계 분석) |
| **그림 4** | 3.0 | 시계열 플롯 *(선택)* | `cell-8, cell-9, cell-10` (섹션 2. 기본 EDA) |
| **그림 5** | 6.0 | 모델별 PA F1 비교 차트 *(실험 후)* | 생성 예정 |
| **그림 6** | 6.0 | 후처리별 성능 비교 *(실험 후)* | 생성 예정 |

> ⚠️ 위 그림들은 현재 플레이스홀더로 표시되어 있습니다.
> Word로 복사 후 실제 이미지로 대체해주세요.
> 📍 노트북 파일: `notebooks/01_data_analysis.ipynb`

---

## 1. 프로젝트 개요

### 1.1 연구 목적

본 프로젝트는 다변량 시계열 이상 탐지(Multivariate Time Series Anomaly Detection)에서 **Prediction-based**와 **Reconstruction-based** 두 가지 대표적인 접근법의 성능을 비교 분석한다.

| 구분 | 내용 |
|------|------|
| **비교 대상** | DLinear (Prediction) vs OmniAnomaly (Reconstruction) |
| **데이터셋** | PSM (서버 머신), SWaT (수처리 시설) |
| **평가 지표** | Point-wise F1, PA F1, ROC-AUC, PR-AUC |

### 1.2 핵심 연구 질문

| 번호 | 연구 질문 |
|------|----------|
| **RQ1** | Prediction-based와 Reconstruction-based 중 어떤 방법론이 더 효과적인가? |
| **RQ2** | 전처리(정규화, Smoothing, Detrending)가 이상 탐지 성능에 미치는 영향은? |
| **RQ3** | 후처리(Threshold, Point Adjustment)가 최종 성능에 미치는 영향은? |
| **RQ4** | 데이터셋 특성(이상치 비율, 구간 길이)에 따른 최적 전략은 무엇인가? |

### 1.3 분석 파이프라인

```
┌──────────┐    ┌──────────────┐    ┌─────────┐    ┌──────────────┐    ┌───────────┐
│   Data   │ → │ Preprocessing │ → │  Model  │ → │ Postprocessing│ → │ Evaluation│
│  Loader  │    │ (Scaler,     │    │(DLinear,│    │ (Threshold,  │    │ (F1, AUC) │
│          │    │  Smoother,   │    │ Omni-   │    │  Point       │    │           │
│          │    │  Detrender)  │    │ Anomaly)│    │  Adjustment) │    │           │
└──────────┘    └──────────────┘    └─────────┘    └──────────────┘    └───────────┘
```

---

## 2. 데이터셋 소개

### 2.1 데이터셋 개요

본 연구에서는 이상 탐지 벤치마크로 널리 사용되는 두 개의 실제 산업 데이터셋을 활용하였다.

| 항목 | PSM (Pooled Server Metrics) | SWaT (Secure Water Treatment) |
|------|----------------------------|-------------------------------|
| **도메인** | 서버 머신 모니터링 | 수처리 시설 제어 시스템 |
| **수집 기관** | eBay | iTrust, SUTD |
| **특징** | 서버 성능 지표 | 물리적 프로세스 센서 |
| **공격 유형** | 시스템 장애/이상 | 사이버-물리 공격 |

### 2.2 데이터 통계

**표 1: 데이터셋 기본 통계**

| 통계 항목 | PSM | SWaT |
|----------|-----|------|
| Train 샘플 수 | 132,481 | 395,298 |
| Test 샘플 수 | 87,841 | 449,919 |
| Feature 수 | 25 | 51 |
| 결측치 | 0 | 0 |
| 이상치 비율 | **27.76%** | **12.14%** |
| 이상치 샘플 수 | 24,381 | 54,621 |
| 정상 샘플 수 | 63,460 | 395,298 |

### 2.3 이상치 분포 특성

**표 2: 이상치 구간 분석**

| 분석 항목 | PSM | SWaT | 해석 |
|----------|-----|------|------|
| 이상치 구간 수 | 72 | 35 | PSM이 더 잦은 이상 발생 |
| 평균 구간 길이 | 338.6 | 1,560.6 | SWaT는 장기 지속 이상 |
| 최대 구간 길이 | 8,861 | - | 연속 이상 구간 존재 |
| 최소 구간 길이 | 1 | - | 순간 이상도 존재 |

> **분석 인사이트**:
> - PSM: 짧고 빈번한 이상치 → Point-wise 평가가 의미 있음
> - SWaT: 길고 연속적인 이상치 → Point Adjustment 평가가 더 적합

### 2.4 이상치 분포 시각화

> **[그림 1 삽입]**
> - **파일 위치**: `notebooks/01_data_analysis.ipynb` - 섹션 5. 이상치 분포 분석 (cell-19)
> - **내용**: PSM/SWaT 이상치 분포 파이 차트 (정상 vs 이상 비율)
> - **형식**: 2개 파이 차트 나란히 배치

---

## 3. 탐색적 데이터 분석 (EDA)

> **[그림 4 삽입]** *(선택사항)*
> - **파일 위치**: `notebooks/01_data_analysis.ipynb` - 섹션 2. 기본 EDA (cell-8, cell-9, cell-10)
> - **내용**: PSM/SWaT 대표 Feature 시계열 플롯 (이상 구간 음영 표시)
> - **형식**: 2-4개 대표 Feature 서브플롯

### 3.1 시계열 정상성 검정

시계열 데이터의 정상성(Stationarity)은 모델 학습에 중요한 영향을 미친다. ADF 검정과 KPSS 검정을 통해 각 feature의 정상성을 분석하였다.

**검정 방법 해석:**
| 검정 | 귀무가설 | p < 0.05 해석 |
|------|---------|--------------|
| ADF (Augmented Dickey-Fuller) | 단위근 존재 (비정상) | 정상 시계열 |
| KPSS (Kwiatkowski-Phillips-Schmidt-Shin) | 정상 시계열 | 비정상 시계열 |

**표 3: 정상성 검정 결과 요약**

| 검정 기준 | PSM | SWaT |
|----------|-----|------|
| ADF 기준 정상 | 25/25 (100.0%) | 50/51 (98.0%) |
| KPSS 기준 정상 | 0/25 (0.0%) | 32/51 (62.7%) |
| **두 검정 모두 정상** | **0/25 (0.0%)** | **23/51 (45.1%)** |

> **분석 인사이트**:
> - **PSM**: ADF 기준 100% 정상이나 KPSS 기준 0% 정상 → **Trend 성분이 강함**
> - **SWaT**: 약 45%만 완전 정상 → **다양한 특성의 feature 혼재**
> - **전처리 필요성**: 두 데이터셋 모두 Detrending 또는 차분(Differencing) 고려 필요

### 3.2 STL 분해 분석

STL(Seasonal and Trend decomposition using Loess) 분해를 통해 시계열의 구성 요소를 분석하였다.

**분해 성분:**
- **Trend**: 장기적 추세 (DLinear가 학습하는 주요 대상)
- **Seasonal**: 주기적 패턴 (DLinear가 학습하는 또 다른 대상)
- **Residual**: 나머지 성분 (**이상치가 여기에 포함**)

> **[그림 2 삽입]**
> - **파일 위치**: `notebooks/01_data_analysis.ipynb` - 섹션 4. Trend/Seasonal 분해 (cell-15)
> - **내용**: PSM 대표 Feature의 STL 분해 결과 (Original, Trend, Seasonal, Residual 4단 그래프)
> - **형식**: 4개 서브플롯 수직 배치

**표 4: PSM 대표 Feature STL 분해 결과**

| 성분 | 분산 비율 | 해석 |
|------|----------|------|
| Trend | ~40-60% | 장기 추세가 상당 부분 차지 |
| Seasonal | ~10-20% | 주기적 패턴 존재 |
| Residual | ~30-40% | 이상치 포함 영역 |

> **분석 인사이트**:
> - Trend 성분이 크면 → **Detrending 전처리가 효과적**
> - Residual에 이상치가 집중 → **정상 패턴 제거 후 이상 탐지 유리**

### 3.3 변수 간 상관관계 분석

다변량 시계열에서 변수 간 상관관계는 이상 탐지의 중요한 단서가 된다.

> **[그림 3 삽입]**
> - **파일 위치**: `notebooks/01_data_analysis.ipynb` - 섹션 6. 상관관계 분석 (cell-21, cell-22)
> - **내용**: PSM/SWaT 상관관계 히트맵
> - **형식**: 2개 히트맵 (PSM 25×25, SWaT 51×51) 나란히 또는 순차 배치

**표 5: 상관관계 분석 요약**

| 분석 항목 | PSM | SWaT |
|----------|-----|------|
| Feature 수 | 25 | 51 |
| 강한 양의 상관 (r > 0.7) | 다수 존재 | 일부 그룹 존재 |
| 강한 음의 상관 (r < -0.7) | 소수 | 거의 없음 |
| 상관 패턴 | 클러스터 형태 | 프로세스별 그룹화 |

> **분석 인사이트**:
> - **PSM**: Feature 간 강한 상관관계 → 다변량 모델(OmniAnomaly)이 유리할 수 있음
> - **SWaT**: 프로세스 단위 그룹화 → 하위 시스템별 이상 패턴 존재

### 3.4 EDA 핵심 발견 요약

| 발견 | PSM | SWaT | 시사점 |
|------|-----|------|--------|
| 이상치 비율 | 높음 (27.8%) | 중간 (12.1%) | PSM이 더 도전적 |
| 이상치 구간 | 짧고 빈번 | 길고 연속적 | 평가 전략 차별화 필요 |
| 정상성 | Trend 강함 | 혼재 | 전처리 중요 |
| 변수 상관 | 높음 | 그룹별 상관 | 다변량 모델 활용 |

---

## 4. 방법론

### 4.1 접근법 비교

**표 6: Prediction-based vs Reconstruction-based 비교**

| 구분 | Prediction-based | Reconstruction-based |
|------|-----------------|---------------------|
| **핵심 아이디어** | 미래 값 예측 후 오차 측정 | 입력 복원 후 오차 측정 |
| **대표 모델** | DLinear, ARIMA, Prophet | OmniAnomaly, VAE, AE |
| **이상 점수** | \|실제 - 예측\| | \|입력 - 복원\| 또는 -log p(x) |
| **장점** | 해석 용이, 빠른 학습 | 복잡한 패턴 학습 가능 |
| **단점** | 비선형 패턴 한계 | 학습 시간 길음, 해석 어려움 |

### 4.2 DLinear (Prediction-based)

**논문**: "Are Transformers Effective for Time Series Forecasting?" (AAAI 2023)

**핵심 구조**:
```
Input Sequence [B, seq_len, C]
        │
        ▼
   Moving Average ──────────────────┐
        │                           │
        ▼                           ▼
    Trend Component          Seasonal Component
        │                           │
        ▼                           ▼
   Linear Layer              Linear Layer
        │                           │
        └───────────┬───────────────┘
                    ▼
            Prediction [B, pred_len, C]
```

**특징**:
| 항목 | 내용 |
|------|------|
| 분해 방식 | Moving Average 기반 Trend/Seasonal 분리 |
| 학습 파라미터 | 선형 레이어만 사용 (경량) |
| 이상 점수 계산 | 예측 오차의 절대값 합 |

### 4.3 OmniAnomaly (Reconstruction-based)

**논문**: "Robust Anomaly Detection for Multivariate Time Series" (KDD 2019)

**핵심 구조**:
```
Input Sequence [B, window_len, x_dim]
        │
        ▼
   GRU Encoder
        │
        ▼
   μ, σ (Latent Parameters)
        │
        ▼
   Planar Normalizing Flow (20 layers)
        │
        ▼
   Latent Variable z
        │
        ▼
   GRU Decoder
        │
        ▼
   Reconstruction [B, window_len, x_dim]
```

**특징**:
| 항목 | 내용 |
|------|------|
| 인코더/디코더 | GRU 기반 시퀀스 모델링 |
| 잠재 공간 | VAE + Normalizing Flow로 유연한 분포 학습 |
| 이상 점수 | 음의 로그 확률 (-log p(x\|z)) |

### 4.4 하이퍼파라미터 설정

**표 7: 모델 하이퍼파라미터 (논문 원본 기준)**

| 파라미터 | DLinear | OmniAnomaly | 비고 |
|---------|---------|-------------|------|
| Window/Seq Length | 100 | 100 | 동일하게 설정 |
| Prediction Length | 1 | - | 1-step ahead |
| Hidden Dimension | - | 500 | GRU hidden |
| Latent Dimension (z_dim) | - | 3 | 잠재 공간 차원 |
| Normalizing Flow Layers | - | 20 | Planar NF |
| Batch Size | 32 | 50 | 논문 원본 |
| Learning Rate | 0.005 | 0.001 | 논문 원본 |
| Weight Decay | - | 1e-4 | L2 정규화 |
| Epochs | 10 (+ Early Stop) | 20 (+ Early Stop) | patience=5 |
| Validation Ratio | 10% | 30% | Early Stopping용 |

---

## 5. 실험 설계

### 5.1 실험 구조 (2-Step 분리)

실험 효율성을 위해 **전처리(재학습 필요)**와 **후처리(재학습 불필요)**를 분리하였다.

```
┌─────────────────────────────────────────────────────────────────────────┐
│                            Step 1: 학습 단계                              │
│  ┌──────────────┐                                                        │
│  │ 4 전처리 조합 │ × 2 모델 × 2 데이터셋 = 16회 학습                        │
│  └──────────────┘                                                        │
│         ↓                                                                │
│  [Anomaly Score 저장] → outputs/scores/                                  │
└─────────────────────────────────────────────────────────────────────────┘
                                    ↓
┌─────────────────────────────────────────────────────────────────────────┐
│                            Step 2: 평가 단계                              │
│  ┌───────────────┐                                                       │
│  │ 저장된 Score  │ × 5 후처리 조합 = 재학습 없이 평가                        │
│  └───────────────┘                                                       │
│         ↓                                                                │
│  [성능 지표 계산] → 80개 조합 결과                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

### 5.2 전처리 실험 조합 (Step 1)

**표 8: 전처리 조합**

| ID | 정규화 | Smoothing | Detrending | 목적 |
|----|--------|-----------|------------|------|
| **P_MM** | MinMaxScaler | - | - | Baseline (0~1 정규화) |
| **P_STD** | StandardScaler | - | - | Z-Score 정규화 비교 |
| **P_SM** | MinMaxScaler | EWMA (span=10) | - | Smoothing 효과 분석 |
| **P_DT** | MinMaxScaler | - | MA (window=24) | Detrending 효과 분석 |

**전처리 선택 근거**:
| 전처리 | 근거 |
|--------|------|
| MinMax vs Standard | 스케일 민감도 비교 |
| EWMA Smoothing | 노이즈 제거, 단기 변동 평활화 |
| MA Detrending | EDA에서 발견된 Trend 성분 제거 |

### 5.3 후처리 실험 조합 (Step 2)

**표 9: 후처리 조합**

| ID | Threshold | Score Smoothing | Relabeling | 목적 |
|----|-----------|-----------------|------------|------|
| **T1** | Fixed (μ + 3σ) | - | - | Baseline |
| **T2** | EWMA Adaptive | - | - | 동적 임계값 효과 |
| **T3** | Fixed (μ + 3σ) | EWMA (span=5) | - | Score 평활화 효과 |
| **T4** | Fixed (μ + 3σ) | EWMA (span=5) | Window Agg | Collective Anomaly |
| **T5** | Fixed (μ + 3σ) | EWMA (span=5) | Point Adjust | PA F1 최적화 |

**후처리 전략 설명**:
| 전략 | 설명 |
|------|------|
| Fixed Threshold (3σ) | 평균 + 3×표준편차 초과 시 이상 판정 |
| EWMA Adaptive | 지수 가중 이동 평균 기반 동적 임계값 |
| Score Smoothing | Anomaly Score에 EWMA 적용하여 노이즈 제거 |
| Point Adjustment | 이상 구간 내 1개 이상 탐지 시 전체 구간 TP 처리 |

### 5.4 평가 지표

**표 10: 평가 지표 정의**

| 지표 | 수식/정의 | 용도 |
|------|----------|------|
| **Point-wise Precision** | TP / (TP + FP) | 탐지 정밀도 |
| **Point-wise Recall** | TP / (TP + FN) | 탐지 재현율 |
| **Point-wise F1** | 2 × (P × R) / (P + R) | 순수 탐지 성능 |
| **PA F1** | Point Adjustment 적용 후 F1 | 실용적 성능 (구간 단위) |
| **ROC-AUC** | ROC 곡선 아래 면적 | 임계값 독립 평가 |
| **PR-AUC** | Precision-Recall 곡선 면적 | 불균형 데이터 평가 |

**Point Adjustment 설명**:
```
[원본 라벨]     0 0 0 1 1 1 1 1 0 0 0
[모델 예측]     0 0 0 0 0 1 0 0 0 0 0
                          ↑
                    이상 구간 내 1개 탐지
                          ↓
[PA 적용 후]    0 0 0 1 1 1 1 1 0 0 0  ← 구간 전체 TP 처리
```

### 5.5 실험 환경

| 항목 | 사양 |
|------|------|
| GPU | NVIDIA GPU × 3 (병렬 학습) |
| Python | 3.8+ |
| Framework | PyTorch 1.9+ |
| 주요 라이브러리 | numpy, pandas, scikit-learn, statsmodels |

---

## 6. 실험 결과

> **[이 섹션은 실험 완료 후 작성 예정]**

> **[그림 5 삽입]** *(실험 완료 후)*
> - **파일 위치**: 실험 결과 시각화 (생성 예정)
> - **내용**: 모델별/전처리별 PA F1 비교 막대 그래프
> - **형식**: Grouped Bar Chart (DLinear vs OmniAnomaly)

> **[그림 6 삽입]** *(실험 완료 후)*
> - **파일 위치**: 실험 결과 시각화 (생성 예정)
> - **내용**: 후처리별 성능 향상 시각화 (T1→T5)
> - **형식**: Point F1 vs PA F1 비교 차트

### 6.1 PSM 데이터셋 결과

**표 11: PSM 전체 결과 (PA F1 기준 정렬)**

| 순위 | 모델 | 전처리 | 후처리 | Point F1 | PA F1 | ROC-AUC | PR-AUC |
|-----|------|--------|--------|----------|-------|---------|--------|
| 1 | - | - | - | - | - | - | - |
| 2 | - | - | - | - | - | - | - |
| ... | ... | ... | ... | ... | ... | ... | ... |

### 6.2 SWaT 데이터셋 결과

**표 12: SWaT 전체 결과 (PA F1 기준 정렬)**

| 순위 | 모델 | 전처리 | 후처리 | Point F1 | PA F1 | ROC-AUC | PR-AUC |
|-----|------|--------|--------|----------|-------|---------|--------|
| 1 | - | - | - | - | - | - | - |
| 2 | - | - | - | - | - | - | - |
| ... | ... | ... | ... | ... | ... | ... | ... |

### 6.3 전처리별 성능 비교

**표 13: 전처리별 평균 PA F1**

| 전처리 | DLinear (PSM) | DLinear (SWaT) | OmniAnomaly (PSM) | OmniAnomaly (SWaT) |
|--------|--------------|----------------|-------------------|-------------------|
| P_MM | - | - | - | - |
| P_STD | - | - | - | - |
| P_SM | - | - | - | - |
| P_DT | - | - | - | - |

### 6.4 후처리별 성능 비교

**표 14: 후처리별 평균 성능 향상**

| 후처리 | Point F1 → PA F1 변화 | 해석 |
|--------|----------------------|------|
| T1 (Baseline) | - | 기준선 |
| T2 (Adaptive) | - | - |
| T3 (Score Smooth) | - | - |
| T4 (Window Agg) | - | - |
| T5 (Point Adjust) | - | - |

### 6.5 모델별 성능 비교

**표 15: DLinear vs OmniAnomaly 최고 성능 비교**

| 데이터셋 | 지표 | DLinear (Best) | OmniAnomaly (Best) | 승자 |
|---------|------|----------------|-------------------|------|
| PSM | PA F1 | - | - | - |
| PSM | ROC-AUC | - | - | - |
| SWaT | PA F1 | - | - | - |
| SWaT | ROC-AUC | - | - | - |

---

## 7. 결과 분석 및 인사이트

> **[이 섹션은 실험 완료 후 작성 예정]**

### 7.1 핵심 발견

**인사이트 1: 모델 비교**
```
┌─────────────────────────────────────────────────────────────────────┐
│ [발견 내용 - 실험 후 작성]                                            │
│                                                                     │
│ • DLinear vs OmniAnomaly 성능 차이                                   │
│ • 각 모델이 강점을 보이는 상황                                         │
│ • 학습 시간 대비 성능 트레이드오프                                      │
└─────────────────────────────────────────────────────────────────────┘
```

**인사이트 2: 전처리 효과**
```
┌─────────────────────────────────────────────────────────────────────┐
│ [발견 내용 - 실험 후 작성]                                            │
│                                                                     │
│ • 가장 효과적인 전처리 조합                                            │
│ • 데이터 특성별 최적 전처리                                            │
│ • EDA 결과와의 연관성                                                 │
└─────────────────────────────────────────────────────────────────────┘
```

**인사이트 3: 후처리 효과**
```
┌─────────────────────────────────────────────────────────────────────┐
│ [발견 내용 - 실험 후 작성]                                            │
│                                                                     │
│ • Point Adjustment의 효과 정량화                                      │
│ • Score Smoothing의 역할                                             │
│ • 최적 후처리 전략                                                    │
└─────────────────────────────────────────────────────────────────────┘
```

### 7.2 Point-wise F1 vs PA F1 분석

| 관점 | 분석 내용 |
|------|----------|
| 차이 발생 원인 | - |
| PA 효과가 큰 경우 | - |
| PA 효과가 작은 경우 | - |

### 7.3 연구 질문에 대한 답변

| 연구 질문 | 답변 |
|----------|------|
| **RQ1**: 어떤 방법론이 더 효과적? | [실험 후 작성] |
| **RQ2**: 전처리의 영향? | [실험 후 작성] |
| **RQ3**: 후처리의 영향? | [실험 후 작성] |
| **RQ4**: 데이터 특성별 최적 전략? | [실험 후 작성] |

### 7.4 한계점

| 한계 | 설명 | 향후 개선 방향 |
|------|------|---------------|
| 1 | - | - |
| 2 | - | - |
| 3 | - | - |

---

## 8. 결론 및 향후 연구

### 8.1 주요 결론

```
┌─────────────────────────────────────────────────────────────────────┐
│                          핵심 결론                                    │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│ 1. [최적 모델]: [실험 후 작성]                                        │
│                                                                     │
│ 2. [최적 파이프라인]: [실험 후 작성]                                   │
│                                                                     │
│ 3. [방법론 비교 결론]: [실험 후 작성]                                  │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

### 8.2 향후 연구 제언

| 방향 | 내용 |
|------|------|
| **모델 확장** | Transformer 기반 모델 (Anomaly Transformer) 비교 |
| **앙상블** | DLinear + OmniAnomaly 앙상블 기법 탐색 |
| **실시간 적용** | 온라인 학습 및 실시간 탐지 시스템 구현 |
| **해석 가능성** | Attention 기반 이상 원인 분석 |

---

## 부록

### A. 참고 문헌

| 모델 | 논문 | 저자 | 학회/연도 |
|------|------|------|----------|
| DLinear | "Are Transformers Effective for Time Series Forecasting?" | Zeng et al. | AAAI 2023 |
| OmniAnomaly | "Robust Anomaly Detection for Multivariate Time Series" | Su et al. | KDD 2019 |

### B. 코드 저장소 구조

```
Anomaly-Detection/
├── src/                    # 소스 코드
│   ├── models/             # 모델 구현
│   ├── preprocessing/      # 전처리 모듈
│   ├── postprocessing/     # 후처리 모듈
│   └── evaluation/         # 평가 모듈
├── scripts/                # 실험 스크립트
├── notebooks/              # EDA 노트북
├── outputs/                # 실험 결과
└── docs/                   # 문서
```

---

**보고서 작성일**: 2025-12-02
**작성 도구**: Claude Code + Python

